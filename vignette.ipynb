{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vignette\n",
    "## Sentiment Analysis of Twitter Users (GitHub: TwitterSentimentAnalysis)\n",
    "\n",
    "### Introduction\n",
    "This package enables users to get a visualized **sentiment analysis** of any selected twitter user on their political sentiment (liberal vs. conservative). Besides an authenticator token (bearer token), only the username (@handle) of an existing twitter user is required. Users get an overall and over-time visualization of the political sentiment of the account in question as well as frequently used words.\n",
    "\n",
    "*It is recommended to run this package through the command line.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to use the package\n",
    "The first step is to copy the repository from GitHub and run the the main.py file in your terminal (the exact execution is explained in the README file). Alternatively, users can run the following code to import the package and use the key function \"get_tweets(username, bearer_token)\" from the class \"Tweets\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install in command line while in package directory (...GitHub\\TwitterSentimentAnalysis):\n",
    "# $ python twitter_sentiment/setup.py install\n",
    "\n",
    "import twitter_sentiment as tws\n",
    "\n",
    "obj = tws.Tweets.Tweets()\n",
    "\n",
    "# Function takes two arguments: username (@handle) and an authenticator token\n",
    "obj.get_tweets(\"username\", \"bearer_token\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of output\n",
    "The output includes a pie chart, time-series chart, wordcloud, and the classification of a randomly selected tweet to illustrate the classification process. The following example charts are based on **Jordan B. Peterson's** twitter account (a Canadian clinical psychologist). The sentiment analysis always considers the last 100 tweets or the available number of tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pie Chart\n",
    "The pie chart hows the **ratio of as liberal vs. conservative classified tweets**. In this case, the user's tweets show a tendency towards a more liberal sentiment. However, over a third of the tweets display a conservative impression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"img/pic_example_pie_chart.png\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time Series Chart\n",
    "The time series chart displays the **probability of sentiments on single tweets** over the given time period in which they were tweeted. The classification does not simply assign a sentiment to each tweet, but a probability with respect to both sentiments, which add up to **1**. The graph also shows a **running average of the last 14 tweets**. This facilitates the localization on the sentiment scale as it gives a more accurate position. In the example, tweet sentiment varies from one to the other extreme, however, the running average indicates a sentiment located in the middle of both expressions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"img/pic_example_time_series.png\" width = \"800\" height = \"440\" /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WordCloud\n",
    "The wordcloud provides a visulaized **overview of frequently used words** within the (up to) 100 tweets. The more often a word has been used, the larger it appears in the final graphic. In our example, the words \"think\", \"life, and \"people\" appear to have made up a significant portion of the overall used terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"img/pic_example_wordcloud.png\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SingleTweet\n",
    "Each execution of the package provides a **random tweet and its respective sentiment**. This serves mainly to illustrate the classification process and enables us to test if the classification aligns with your own intuitions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"img/pic_example_single_tweet.PNG\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Under the hood\n",
    "#### How does the classifying work?\n",
    "The package uses a pre-trained classifier that was build using the **NaiveBayesClassifier** class from the Natural Language Toolkit (nltk). This classifier represents a simple probabilistics classifier that applies the **Bayes' theorem**. The used classifier makes the 'naive' assumption that all features are independent and assigns each tweet the probability of belonging to either sentiment (both probabilities add up to 1).\n",
    "\n",
    "*More information on how this classifier works: https://www.nltk.org/_modules/nltk/classify/naivebayes.html*\n",
    "\n",
    "#### Note: Pre-Trained Classifier\n",
    "The default classifier (*pol_classifier_30k*) has an accuracy of around 80% (validation on test data set). The classifier was trained on 30.000 tweets from 15 republican ('Conservative') and 15 democratic ('Liberal') U.S. politicians who are active on twitter. Even for twitter users with a clear conservative background, the classifier more often than not classifies a considerable amount of tweets as 'liberal'. This may be due to the fact that the tweets by 'Conservative' politicians used in training the classifier contain more explicit and specfic (politicial) language than their 'Liberal' counterparts. The average twitter user's sentences are closer to natural language and, thus, might be considered 'Liberal' by the classifier.\n",
    "\n",
    "#### Doing your own sentiment analysis\n",
    "The package includes a python script detailing how the classifier was build. Users are invited to do their own sentiment analysis using the provided script or replicate the provided classifier. As for the usage of the package functionalities, an authenticator token (bearer token) for Twitter's API is required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"img/pic_example_bayes.PNG\" width = \"300\" height = \"300\"/></center>"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "929ac0cc281b19fe5954736c0aa51ef858b21c9ddc8d8b98636a363a6f68e962"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
